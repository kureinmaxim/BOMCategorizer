#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä BOM —Ñ–∞–π–ª–æ–≤
–ó–∞–ø—É—Å–∫: python interactive_classify_improved.py --input "–ë–ó.doc"
"""

import os
import sys
import json
import argparse
import pandas as pd
from typing import List, Dict, Any

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ —Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
if sys.stdout.encoding != 'utf-8':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except AttributeError:
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

from split_bom import (
    parse_docx, parse_txt_like, normalize_column_names, 
    find_column, classify_row, has_any
)


def load_rules(rules_path: str = "rules.json") -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–∞–≤–∏–ª"""
    if os.path.exists(rules_path):
        try:
            with open(rules_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∞–≤–∏–ª–∞: {e}")
    return []


def save_rules(rules: List[Dict[str, Any]], rules_path: str = "rules.json"):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª"""
    try:
        with open(rules_path, "w", encoding="utf-8") as f:
            json.dump(rules, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ –ü—Ä–∞–≤–∏–ª–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {rules_path}")
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–∞–≤–∏–ª–∞: {e}")


def get_category_display() -> List[tuple]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    return [
        ("resistors", "–†–µ–∑–∏—Å—Ç–æ—Ä—ã"),
        ("capacitors", "–ö–æ–Ω–¥–µ–Ω—Å–∞—Ç–æ—Ä—ã"),
        ("inductors", "–î—Ä–æ—Å—Å–µ–ª–∏/–ö–∞—Ç—É—à–∫–∏"),
        ("ics", "–ú–∏–∫—Ä–æ—Å—Ö–µ–º—ã"),
        ("connectors", "–†–∞–∑—ä–µ–º—ã"),
        ("dev_boards", "–û—Ç–ª–∞–¥–æ—á–Ω—ã–µ –ø–ª–∞—Ç—ã"),
        ("optics", "–û–ø—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"),
        ("rf_modules", "–°–í–ß –º–æ–¥—É–ª–∏"),
        ("cables", "–ö–∞–±–µ–ª–∏"),
        ("power_modules", "–ú–æ–¥—É–ª–∏ –ø–∏—Ç–∞–Ω–∏—è"),
        ("diods", "–î–∏–æ–¥—ã/–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã"),
        ("our_developments", "–ù–∞—à–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏"),
        ("others", "–î—Ä—É–≥–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"),
        ("skip", "‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–æ—Ç —ç–ª–µ–º–µ–Ω—Ç"),
    ]


def interactive_classify(input_file: str, output_file: str = "categorized.xlsx", 
                         rules_path: str = "rules.json", sheets: str = None):
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Å–æ–∑–¥–∞–Ω–∏–µ–º –ø—Ä–∞–≤–∏–ª"""
    
    print("\n" + "="*80)
    print("üîç –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† BOM –§–ê–ô–õ–û–í")
    print("="*80)
    print(f"üìÅ –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_file}")
    print(f"üìÑ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_file}")
    print(f"üìã –§–∞–π–ª –ø—Ä–∞–≤–∏–ª: {rules_path}")
    print("="*80 + "\n")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    ext = os.path.splitext(input_file)[1].lower()
    
    if ext == ".txt":
        df = parse_txt_like(input_file)
    elif ext == ".docx":
        df = parse_docx(input_file)
    elif ext == ".doc":
        # –ü–æ–ø—ã—Ç–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Word COM
        try:
            from win32com.client import Dispatch
            word = Dispatch("Word.Application")
            word.Visible = False
            doc = word.Documents.Open(os.path.abspath(input_file))
            tmp_docx = os.path.splitext(os.path.abspath(input_file))[0] + "_conv_temp.docx"
            doc.SaveAs(tmp_docx, FileFormat=12)  # wdFormatXMLDocument
            doc.Close(False)
            word.Quit()
            df = parse_docx(tmp_docx)
            os.remove(tmp_docx)
        except Exception:
            print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å .doc, –ø—Ä–æ–±—É—é –∫–∞–∫ —Ç–µ–∫—Å—Ç...")
            df = parse_txt_like(input_file)
    else:  # xlsx
        df = pd.read_excel(input_file, engine="openpyxl")
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–æ–Ω–æ–∫
    original_cols = list(df.columns)
    lower_cols = normalize_column_names(original_cols)
    rename_map = {orig: norm for orig, norm in zip(original_cols, lower_cols)}
    df = df.rename(columns=rename_map)
    
    # –ù–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏
    ref_col = find_column(["ref", "reference", "designator", "–æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ", "–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ"], list(df.columns))
    desc_col = find_column(["description", "desc", "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–∏–º—è", "item", "part name"], list(df.columns))
    value_col = find_column(["value", "–∑–Ω–∞—á–µ–Ω–∏–µ", "–Ω–æ–º–∏–Ω–∞–ª"], list(df.columns))
    part_col = find_column(["partnumber", "mfr part", "mpn", "pn", "art", "–∞—Ä—Ç–∏–∫—É–ª", "part"], list(df.columns))
    
    # –ü–µ—Ä–≤–∏—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    print("‚è≥ –í—ã–ø–æ–ª–Ω—è—é –ø–µ—Ä–≤–∏—á–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é...\n")
    categories = []
    for _, row in df.iterrows():
        ref = row.get(ref_col) if ref_col else None
        desc = row.get(desc_col) if desc_col else None
        val = row.get(value_col) if value_col else None
        part = row.get(part_col) if part_col else None
        categories.append(classify_row(ref, desc, val, part, strict=True))
    
    df["category"] = categories
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
    unclassified = df[df["category"] == "unclassified"].copy()
    
    if len(unclassified) == 0:
        print("‚úÖ –í—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!")
        return
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print(f"   ‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {len(df) - len(unclassified)}")
    print(f"   ‚ùì –¢—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è: {len(unclassified)}")
    print("\n" + "="*80 + "\n")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞
    rules = load_rules(rules_path)
    cat_display = get_category_display()
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    new_rules_count = 0
    
    for idx, (df_idx, row) in enumerate(unclassified.iterrows(), start=1):
        ref = row.get(ref_col) if ref_col else ""
        desc = row.get(desc_col) if desc_col else ""
        val = row.get(value_col) if value_col else ""
        part = row.get(part_col) if part_col else ""
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        display_parts = []
        if pd.notna(ref) and str(ref).strip():
            display_parts.append(f"[{ref}]")
        if pd.notna(desc) and str(desc).strip():
            display_parts.append(str(desc))
        if pd.notna(val) and str(val).strip():
            display_parts.append(f"(–ó–Ω–∞—á: {val})")
        
        display_text = " ".join(display_parts)
        if not display_text.strip():
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        
        print(f"\n{'‚îÄ'*80}")
        print(f"–≠–ª–µ–º–µ–Ω—Ç {idx} –∏–∑ {len(unclassified)}:")
        print(f"{'‚îÄ'*80}")
        print(f"üìù {display_text[:150]}")
        print(f"{'‚îÄ'*80}")
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é:")
        
        for i, (cat_key, cat_name) in enumerate(cat_display, start=1):
            print(f"  {i:2d}. {cat_name}")
        
        print("\n  0. ‚ùå –û—Å—Ç–∞–≤–∏—Ç—å –Ω–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º")
        print("  q. üö™ –í—ã–π—Ç–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å")
        
        while True:
            try:
                choice = input("\nüëâ –í–∞—à –≤—ã–±–æ—Ä: ").strip().lower()
                
                if choice == "q":
                    print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
                    if new_rules_count > 0:
                        save_rules(rules, rules_path)
                    return
                
                if choice == "" or choice == "0":
                    print("‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ")
                    break
                
                choice_num = int(choice)
                if 1 <= choice_num <= len(cat_display):
                    selected_cat = cat_display[choice_num - 1][0]
                    
                    if selected_cat == "skip":
                        print("‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ")
                        break
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                    df.loc[df_idx, "category"] = selected_cat
                    
                    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏—è
                    rule_text = str(desc)[:100] if pd.notna(desc) else ""
                    if rule_text.strip():
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–≥–æ –ø—Ä–∞–≤–∏–ª–∞
                        rule_exists = any(
                            rule.get("contains", "").lower() in rule_text.lower() or
                            rule_text.lower() in rule.get("contains", "").lower()
                            for rule in rules
                        )
                        
                        if not rule_exists:
                            new_rule = {
                                "contains": rule_text.strip(),
                                "category": selected_cat
                            }
                            rules.append(new_rule)
                            new_rules_count += 1
                            print(f"‚úÖ –ü—Ä–∞–≤–∏–ª–æ —Å–æ–∑–¥–∞–Ω–æ! (–≤—Å–µ–≥–æ –Ω–æ–≤—ã—Ö –ø—Ä–∞–≤–∏–ª: {new_rules_count})")
                        else:
                            print(f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∞ (–ø—Ä–∞–≤–∏–ª–æ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)")
                    else:
                        print(f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∞")
                    
                    break
                else:
                    print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞")
            except ValueError:
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ {}, –∏–ª–∏ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞".format(len(cat_display)))
            except KeyboardInterrupt:
                print("\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                if new_rules_count > 0:
                    save_rules(rules, rules_path)
                return
    
    print("\n" + "="*80)
    print("üéâ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("="*80)
    print(f"‚úÖ –ù–æ–≤—ã—Ö –ø—Ä–∞–≤–∏–ª —Å–æ–∑–¥–∞–Ω–æ: {new_rules_count}")
    
    if new_rules_count > 0:
        save_rules(rules, rules_path)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ {output_file}...")
    
    # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å –Ω–æ–≤—ã–º–∏ –ø—Ä–∞–≤–∏–ª–∞–º–∏
    print("\nüîÑ –ó–∞–ø—É—Å–∫–∞—é –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å –Ω–æ–≤—ã–º–∏ –ø—Ä–∞–≤–∏–ª–∞–º–∏...")
    print("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É:")
    print(f"   python split_bom.py --inputs \"{input_file}\" --xlsx \"{output_file}\" --assign-json \"{rules_path}\" --combine")


def main():
    parser = argparse.ArgumentParser(
        description="–£–ª—É—á—à–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä BOM —Ñ–∞–π–ª–æ–≤",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python interactive_classify_improved.py --input "example/–ë–ó.doc"
  python interactive_classify_improved.py --input "example/bom.xlsx" --output result.xlsx
  python interactive_classify_improved.py --input "bom.xlsx" --rules custom_rules.json
        """
    )
    
    parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (XLSX/DOC/DOCX/TXT)")
    parser.add_argument("--output", default="categorized.xlsx", help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É XLSX —Ñ–∞–π–ª—É")
    parser.add_argument("--rules", default="rules.json", help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø—Ä–∞–≤–∏–ª–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: rules.json)")
    parser.add_argument("--sheets", help="–ù–æ–º–µ—Ä–∞/–∏–º–µ–Ω–∞ –ª–∏—Å—Ç–æ–≤ –¥–ª—è XLSX (–Ω–∞–ø—Ä–∏–º–µ—Ä: 3,4)")
    
    args = parser.parse_args()
    
    try:
        interactive_classify(args.input, args.output, args.rules, args.sheets)
    except KeyboardInterrupt:
        print("\n\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

